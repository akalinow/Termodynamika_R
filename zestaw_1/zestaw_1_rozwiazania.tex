\documentclass[11pt,a4paper]{article}

\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage[T1]{fontenc}
\usepackage{indentfirst}
\usepackage{wrapfig}    % for wrapping figures, tables
\usepackage{isotope}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{gensymb}
\usepackage{epsfig}
\usepackage{graphics}
\usepackage[shortlabels]{enumitem}
\usepackage{xspace}
\xspaceaddexceptions{[]\{\}}

%
%
%fixpagesize
\pagestyle{empty}
\addtolength{\textwidth}{4cm}
\addtolength{\textheight}{6cm}
\addtolength{\evensidemargin}{-3cm}
\addtolength{\oddsidemargin}{-2cm}
\addtolength{\topmargin}{-3cm}
\parindent=0cm

%
%
% Changes figure placing algorithm
\renewcommand{\topfraction}{1}       % maximal fraction of a page allowed for figures
\renewcommand{\textfraction}{0.15}   % minimal number of text for figure-text shared pages
\renewcommand{\floatpagefraction}{0.95} % if two above does not help, this could do the job 
                                        % must be: floatpagefraction < topfraction !!!!
\renewcommand{\textfraction}{0} % minimum fraction of page, which must be  devoted to text
\renewcommand{\topfraction}{1}  % maximum fraction at top, which can be occupied whit floats
\setcounter{totalnumber}{400}   % increase the number of floats for one page
\setcounter{topnumber}{200}     % at all/top/bottom.
\setcounter{bottomnumber}{200}  %

%
%
%small distance in list/item/enum for enumitem package
\setlist[itemize,enumerate]{topsep=0em}
\setlist{noitemsep}

%Nuclear notations: usage \nucl{235}{92}{U}. Math mode optional
\newcommand{\nucl}[3]{\ensuremath{
  \phantom{\ensuremath{^{#1}_{#2}}}
  \llap{\ensuremath{^{#1}}}
  \llap{\ensuremath{_{\rule{0pt}{.75em}#2}}}
  \mbox{#3} } 
} 

%print zadanie #
\newcounter{zadanie}\newcommand{\zadanie}[1][]{\addtocounter{zadanie}{1} ~\\  {\bf \emph{Zadanie \arabic{zadanie} #1 }} \\}
\newcounter{zaddom}\newcommand{\zaddom}[1][]{\addtocounter{zaddom}{1} ~\\  {\bf \emph{Zadanie domowe \arabic{zaddom} #1 }} \\}

%dynamic solutions hiding
\usepackage{comment}

\newif\ifshowsolutions

\def\showsolutions{}  %← show solutions. Comment out to hide solutions

\newif\ifshowsolutions
\ifdefined\showsolutions
  \showsolutionstrue
\else
  \showsolutionsfalse
\fi

\ifshowsolutions
  \newenvironment{solution}{\vspace{1cm} \par\textbf{Rozwiązanie.} \vspace{1cm}}{}
\else
  \excludecomment{solution}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}         

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{centering}
  {\bf {\Large
  Termodynamika i Fizyka Statystyczna R \\
  Zestaw I: Rachunek prawdopodobieństwa
  }} \\  
\end{centering}

\vspace{1cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Rosyjska ruletka]
W grze w rosyjską ruletkę umieszcza się pojedynczy nabój w bębenku sześciostrzałowego rewolweru. Potem obraca się bębenkiem, celuje w głowę i pociąga za spust.
Jakie jest prawdopodobieństwo:
\begin{enumerate}[(a)]
    \item pozostania przy życiu po $N$ rundach ruletki?
    \item zostania postrzelonym w $N$-tej rundzie, po przeżyciu poprzednich $N-1$?
\end{enumerate}

{\bf Wskazówka:} zdarzenia są niezależne:
\[P(A \cap B) = P(A)P(B)
\]


\begin{solution}

Prawdopodobieństwo pozostania przy życiu w każdej rundzie, $p_{0}$, to:
\begin{align*}
    p_{0} = \frac{5}{6}
\end{align*}

Prawdopodobieństwo postrzału, $p_{1}$, w każdej rundzie to:
\begin{align*}
    p_{1} = 1 - p_{0} = 1 - \frac{5}{6} = \frac{1}{6}
\end{align*}

Poszczególne próby są niezależne, więc prawdopodobieństwo 
pozostania przy życiu po $N$ rundach to iloczyn prawdopodobieństw, $p_{0}$
pozostania przy życiu w każdej z rund:


\begin{enumerate}[(a)]
    \item Prawdopodobieństwo pozostania przy życiu po $N$ rundach ruletki:
    \[ P = \left(\frac{5}{6}\right)^N \]
    \item Prawdopodobieństwo zostania postrzelonym w $N$-tej rundzie, po przeżyciu poprzednich $N-1$:
    \[ P = \left(\frac{5}{6}\right)^{N-1} \left(\frac{1}{6}\right) \]
\end{enumerate}

Czy założenie $p_{1}=1/6$ jest realistyczne? \\

Wyobraźmy sobie jednorodny cylinder  (bębenek) z dodatkowym obciążeniem (nabojem)
które łamie jego symetrię obrotową. Jaka orientacja bębenka minimalizuje
energię układu?

W grze zwykle bierze udział więcej niż jeden zawodnik. W tej sytuacji trzeba 
uwzględnić, prawdopodobieństwo zakończenia gry w każdej rundzie, przez 
pozostałych graczy.


\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Dwie papugi]
Miała baba dwie papugi.
\begin{enumerate}[(a)]
    \item Na pytanie: Czy przynajmniej jedna z papug to samiec? \\
    odpowiedziała -- Tak \\
    \item Na pytanie: Czy ta papuga to samiec? \\
    odpowiedziała -- Tak
\end{enumerate}

Jakie jest prawdopodobieństwo tego, że obie papugi to samce 
w każdym z powyższych przypadków?

\begin{solution}
    
\begin{enumerate}[(a)]
    \item wypiszmy wszystkie możliwe kombinacje płci papug, 
          które spełniają warunek, że przynajmniej jedna z nich jest samcem:
            \begin{itemize}
                \item Samiec - Samiec
                \item Samiec - Samica
                \item Samica - Samiec
            \end{itemize}
          Kombinacji jest 3, z czego tylko jedna spełnia warunek,           
          że obie papugi to samce, więc prawdopodobieństwo wynosi $\frac{1}{3}$.
          Istotnym faktem jest że nie wiemy która z papug jest samcem, 
          więc musimy uwzględnić obie możliwości, że samiec jest pierwszą 
          lub drugą papugą.\\
    \item sytuacja jest prostrza, ponieważ wiemy, że jedna, {\bf konkretna} papuga 
          jest samcem, więc mamy tylko dwie możliwości:
            \begin{itemize}
                \item Samiec - Samiec
                \item Samiec - Samica
            \end{itemize}
          Kombinacji jest 2, z czego tylko jedna spełnia warunek,           
          że obie papugi to samce prawdopodobieństwo wynosi $\frac{1}{2}$
\end{enumerate}

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Ława przysięgłych]

Rozważ dwie ławy przysięgłych:
\begin{enumerate}[A:]
    \item trzysobowa ława przysięgłych składa się z dwóch ``porządnych ludzi'', 
    każdy z których (niezależnie) wydaje sprawiedliwy wyrok z prawdopodobieństwem 
    $p$ oraz osobnika który po prostu rzuca monetą przed wydaniem wyroku. 
    Ostateczna decyzja ławy jest podejmowana większością głosów.
    \item jednosobowa składa się z jednego porządnego człowieka, 
    który wydaje sprawiedliwy wyrok z prawdopodobieństwem $p$.
\end{enumerate}

Która z tych ław przysięgłych wyda sprawiedliwy wyrok z większym prawdopodobieństwem?

\begin{solution}
    
Prawdopodobieństwo, sprawiedliwego wyroku dla ławy A:\\
Sprawiedliwy wyrok będzie wydany jeśli dwu ławników wyda sprawiedliwy wyrok.
Prawdopodobieństwo takiej konfiguracji możemy to obliczyć na dwa sposoby:
\begin{itemize}
    \item bezpośrednio, wypisując wszystkie możliwe kombinacje:
    \begin{itemize}
        \item obu sprawiedliwych "trafiło", nie ma znaczenia wyrok trzeciego: $p^{2}$
        \item jeden sprawiedliwy trafił, drugi nie, a losowy wyrok jest sprawiedliwy.
               W tym wypadku musimy uwzględnić, że sprawiedliwych jest dwu:
               $2 p\cdot(1-p) \cdot \frac{1}{2}$
    \end{itemize}
    Sumując oba przypadki otrzymujemy:
    \begin{align*}
        P_A &= p^{2} + 2 p\cdot(1-p) \cdot \frac{1}{2} = p^{2} + p\cdot(1-p) = p
    \end{align*}

    \item obliczając prawdopodobieństwo, błędnego wyroku i biorąc jego dopełnienie:
    \begin{itemize}
        \item obu sprawiedliwych "spudłowało", nie ma znaczenia wyrok trzeciego: $(1-p)^{2}$
        \item jeden sprawiedliwy trafił, drugi nie, a losowy wyrok jest błędny.
               W tym wypadku musimy uwzględnić, że sprawiedliwych jest dwu:
               $2 p\cdot(1-p) \cdot \frac{1}{2}$
    \end{itemize}
    Sumując oba przypadki otrzymujemy prawdopodobieństwo błędnego wyroku:
    \begin{align*}
        P_{\text{błędny}} &= (1-p)^{2} + 2 p\cdot(1-p) \cdot \frac{1}{2} = (1-p)^{2} + p\cdot(1-p) = 1 - p
    \end{align*}
    a zatem prawdopodobieństwo sprawiedliwego wyroku to:
    \begin{align*}        
        P_A &= 1 - P_{\text{błędny}} = p
    \end{align*}
\end{itemize}
       
Prawdopodobieństwo sprawiedliwego wyroku dla ławy B to po prostu $p$.
Podsumowując: obie ławy przysięgłych wydadzą sprawiedliwy wyrok z takim 
samym prawdopodobieństwem $p$.

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Teleturniej ``Idź na całość'']

Gracz ma wybrać jedne z trzech drzwi: A, B, C. Za jednymi z nich jest cenna nagroda.
Prowadzący turniej wie  gdzie jest nagroda.

Gra składa się z dwóch etapów:
\begin{enumerate}
    \item gracz wskazuje losowo jedne z drzwi: A 
    \item prowadzący turniej otwiera 
    jedne z pozostałych drzwi, za którymi nagrody {\bf nie ma}: B
    \item prowadzący pyta gracza: ``Pozostajesz przy swoim wyborze czy go zmieniasz?''.
\end{enumerate}
 
Co ma zrobić gracz by zmaksymalizować prawdopodobieństwo wygranej, $p$?\\
Ile wynosi $p$ w przypadku pozostania przy swoim wyborze, 
a ile w przypadku zmiany wyboru?


\begin{solution}

Rozważmy oba warianty:
\begin{itemize}
    \item pozostanie przy swoim wyborze: gracz wygra tylko wtedy, 
          gdy jego pierwotny wybór był trafny, a prawdopodobieństwo 
          tego wynosi po prostu $\frac{1}{3}$.
    \item zmiana wyboru: gracz wygra wtedy, gdy jego pierwotny wybór był nietrafny,
          a prawdopodobieństwo tego wynosi $\frac{2}{3}$.
\end{itemize}


Podsumowując: gracz powinien zmienić swój wybór.

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Błądzący pijak]

Osoba pod wpływem środków odurzających stoi o krok od przepaści.
Osoba ta wykonuje losowe kroki w kierunku przepaści, 
z prawdopodobieństwem $p_{0} = \frac{1}{3}$, albo w kierunku przeciwnym.
Jakie jest prawdopodobieństwo uniknięcia upadku w granicy $t \to \infty$?

\begin{solution}


Niech $p^{+}$ oznacza prawdopodobieństwo, że będąc na pozycji $n+1$ 
pijak, {\bf kiedykolwiek}, znajdzie się na pozycji $n$ (=bliżej przepaści).
Rozważmy co się stanie, gdy pijak wykona pierwszy krok:

\begin{itemize}
    \item krok w kierunku przepaści (z prawdopodobieństwem $p_0$): od razu 
    znajduje się na $n$ 
    \item krok w kierunku przeciwnym (z prawdopodobieństwem $1-p_0$): znajduje 
          się teraz na $n+2$. Aby znaleźć się na $n$ musi najpierw przesunąć
          się na $n+1$ - to zachodzi z prawdopodobieństwem $p^{+}$ 
          - a potem z $n+1$ na $n$ - to także z prawdopodobieństwem $p^{+}$.
          Zatem prawdopodobieństwo przejścia 
          z $n+2$ do $n$ to przejście $2 \to 1$ - z prawdopodobieństwem $p^{+}$,  
          i potem $1 \to 0$ - z prawdopodobieństwem $p^{+}$,
          co daje łącznie ${p^{+}}^2$
\end{itemize}

Zatem możemy zapisać:
\begin{align*}
    p^{+} = p_0 \cdot 1 + (1-p_0) \cdot (p^{+})^2
\end{align*}

Rozwiązaniem tego równania są:
\begin{align*}
    p^{+} = 1 \quad \text{or} \quad p^{+} = \frac{p_0}{1-p_0}
\end{align*} 

Rozwiązanie $p^{+} = 1$ jest odrzucamy jako niefizyczne, 
ponieważ nie zależy od $p_{0}$, więc np. dla $p_{0} = 0$
jest błędne.

Wstawiając $p_0 = \frac{1}{3}$ otrzymujemy:
\begin{align*}
 \quad p^{+} = \frac{1/3}{1-1/3} = \frac{1}{2}
\end{align*}

Więc prawdopodobieństwo uniknięcia upadku to $1 - p^{+} = \frac{1}{2}$.

\vspace{2cm}
Inaczej z wykorzystaniem równania typu Master:


Niech $p(n)$ oznacza prawdopodobieństwo uniknięcia upadku, 
zaczynając z pozycji $n$ kroków od przepaści. 
Zależnie od kierunku ruchu w danym kroku czasowym prawdopodobieństwa 
uniknięcia upadku można wyrazić jako:

\begin{itemize}
\item $p_0 \cdot p(n-1)$ - ruch w kierunku przepaści 
\item $(1-p_0) \cdot p(n+1)$ - ruch w kierunku przeciwnym 
\end{itemize}

Więc prawdopodobieństwo uniknięcia upadku to suma tych dwóch wariantów:
\[
p(n) = p_0 \cdot p(n-1) + (1-p_0) \cdot p(n+1),
\]

Warunki brzegowe to:
\begin{itemize}
\item $p(0) = 0$ - jeśli osoba osiągnie przepaść, to spada
\item $p(\infty) = 1$ - jeśli jest nieskończenie daleko od przepaści, to 
                   nigdy do niej nie dojdzie
\end{itemize}

Dostaliśmy równanie rekurencyjne, ale poradzimy sobie z nim.
Przekształcamy równanie rekurencyjne:
\begin{align*}
    p(n) + p_{0}p(n) = p_0 \cdot p(n-1) + (1-p_0) \cdot p(n+1) + p_{0}p(n) \\
    p_{0}[p(n) - p(n-1)] = (1-p_0)(p(n+1) - p(n)) \\
    \frac{p_0}{1-p_0} \cdot [p(n) - p(n-1)\big] = p(n+1) - p(n)
\end{align*}

Oznaczmy $Q(n) = p(n) - p(n-1)$. Wtedy:
\begin{align*}
Q(n+1) = \frac{p_0}{1-p_0} \cdot Q(n) \rightarrow 
\frac{Q(n+1)}{Q(n)} = \frac{p_0}{1-p_0} = q
\end{align*}

Otrzymaliśmy więc ciąg geometryczny o ilorazie $q = \frac{p_0}{1-p_0}$, więc
Q(n) możemy wyrazić przez $Q(1)$:

\begin{align*}
Q(n) = Q(1) \cdot \left(\frac{p_0}{1-p_0}\right)^{n-1}.
\end{align*}

$Q(n)$ to różnica $p(n) - p(n-1)$, więc możemy znaleźć $p(n)$ 
sumując $Q(k)$ od 1 do n:

\begin{align*}
p(n) &= \sum_{k=1}^n Q(k) = \\
     &= Q(1) \cdot \sum_{k=1}^n \left(\frac{p_0}{1-p_0 }\right)^{k-1} = \\
     &= Q(1) \cdot \frac{1 - \left(\frac{p_0}{1-p_0}\right)^n}{1 - \frac{p_0}{1-p_0}}
\end{align*}

Wartość $Q(1)$ wyznaczamy z warunku brzegowego $p(\infty) = 1$.
Zauważmy że p(n) jest skończone dla 
\begin{align*}
\left(\frac{p_0}{1-p_0 }\right) <1 \rightarrow p_0 < \frac{1}{2}
\end{align*}

\begin{align*}
p(\infty) = \lim_{n \to \infty} Q(1) \cdot \frac{1 - \left(\frac{p_0}{1-p_0}\right)^n}{1 - \frac{p_0}{1-p_0}} = \\
Q(1) \cdot \frac{1}{1 - \frac{p_0}{1-p_0}} =  Q(1) \frac{1-2p_0}{1-p_0} = 1 \rightarrow \\
Q(1) = \frac{1-2p_0}{1-p_0}.
\end{align*}

Ostatecznie:
\begin{align*}
p(n) = \frac{1-2p_0}{1-p_0} \frac{1 - \left(\frac{p_0}{1-p_0}\right)^n}{1 - \frac{p_0}{1-p_0}} = \\
\frac{1-2p_0}{1-p_0} \cdot \frac{1-p_0}{1-2p_0} \cdot \left[1 - \left(\frac{p_0}{1-p_0}\right)^n\right] = \\
1 - \left(\frac{p_0}{1-p_0}\right)^n = 1 - (p^{+})^n
\end{align*}

Dla $p_0 = \frac{1}{3}$ i $n=1$ otrzymujemy:
\begin{align*}
p(n) = 1 - \left(\frac{1/3}{1-1/3}\right) = 1 - \left(\frac{1}{2}\right) = \frac{1}{2}
\end{align*}

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Błądzący pijak w 2D - problem Polya'i]

Pijak z poprzedniego zadania jest w punkcie A i 
w każdym odcinku czasu przesuwa się o jeden krok 
albo na północ albo na południe i jednocześnie 
jeden krok albo na wschód albo na zachód (czyli chodzi po "przekątnych"). 
Oblicz prawdopodobieństwo powrotu do punktu początkowego.

\begin{solution}

Oznaczmy $p(0|2n)$ jako prawdopodobieństwo znalezienia się w odległości $x=0$ 
od punktu początkowego po $2n$ krokach. Ruch w obu kierunkach jest niezależny,
a kroki zachodzą z takim samym prawdopodobieństwem, 
więc $ p_{x}(0|2n) = p_{y}(0|2n)$. By być w odległości $x=0$ po $2n$ krokach,
trzeba wykonać równą liczbę kroków w kierunku "do przodu" i "do tyłu".

Prawdopodobieństwo takiej konfiguracji to:
\begin{align*}
p_{\text{konf}}(0|2n) = \frac{1}{2}^{n} \cdot \frac{1}{2}^{n}
\end{align*}

Musimy jeszcze uwzględnić liczbę konfiguracji, które spełniają warunek $x=0$.
Liczba takich konfiguracji to liczba sposobów wyboru $n$ kroków "do przodu" 
spośród $2n$ kroków, czyli:
\begin{align*}
C(2n, n) = \frac{(2n)!}{n! \cdot n!}
\end{align*}

Ostatecznie prawdopodobieństwo znalezienia się w odległości $x=0$ po $n$ krokach to:
\begin{align*}
p(0|2n) = C(2n, n) \cdot p_{\text{konf}}(0|2n) = \frac{(2n)!}{n! \cdot n!} \cdot \frac{1}{2}^{2n}
\end{align*}

Prawdopodobieństwo ruchu w obu kierunkach są niezależne, 
i takie same, więc prawdopodobieństwo powrotu do punktu początkowego 
po $2n$ krokach to:
\begin{align*}
p_{\text{2D}}(2n) = p(0|2n) \cdot p(0|2n) = \left(\frac{(2n)!}{n! \cdot n!} \cdot \frac{1}{2}^{2n}\right)^2
\end{align*}

Zajmijmy się teraz asymptotycznym zachowaniem tego prawdopodobieństwa dla dużych $n$.
Korzystamy z przybliżenia Stirlinga dla silni:
\begin{align*}
n! \approx \sqrt{2\pi n} \left(\frac{n}{e}\right)^n
\end{align*}

Zatem:
\begin{align*}
\frac{(2n)!}{n! \cdot n!} \approx \frac{\sqrt{4\pi n} \left(\frac{2n}{e}\right)^{2n}}{\left(\sqrt{2\pi n} \left(\frac{n}{e}\right)^n\right)^2} = \frac{\sqrt{4\pi n} \left(\frac{2n}{e}\right)^{2n}}{2\pi n \left(\frac{n}{e}\right)^{2n}} = \\
\frac{\sqrt{4\pi n} \cdot 2^{2n} \cdot n^{2n} \cdot e^{-2n}}{2\pi n \cdot n^{2n} \cdot e^{-2n}} = \frac{\sqrt{4\pi n} \cdot 2^{2n}}{2\pi n} = 
\frac{2^{2n}}{\sqrt{\pi n}}
\end{align*}    

Czyli $p(0|2n)$ można przybliżyć jako:
\begin{align*}
p(0|2n) \approx \frac{2^{2n}}{\sqrt{\pi n}} \cdot \frac{1}{2}^{2n} = \frac{1}{\sqrt{\pi n}}
\end{align*}

Prawdopodobieństwo powrotu do punktu początkowego po $2n$ krokach to:
\begin{align*}
p_{\text{2D}}(2n) \approx \left(\frac{1}{\sqrt{\pi n}}\right)^2 = \frac{1}{\pi n}
\end{align*}

Prawdopodobieństwo powrotu do punktu początkowego w dowolnej liczbie kroków 
to suma prawdopodobieństw powrotu po $2n$ krokach dla wszystkich $n$:
\begin{align*}
P_{\text{powrót}} = \sum_{n=1}^{\infty} p_{\text{2D}}(2n) \approx \sum_{n=1}^{\infty} \frac{1}{\pi n}
\end{align*}

Szereg $\sum_{n=1}^{\infty} \frac{1}{n}$ jest rozbieżny, więc $P_{\text{powrót}}$ 
jest nieskończone, w szczególności $P_{\text{powrót}} > 1$. Oznacza to, że pijak 
z wielokrotnie powróci do punktu początkowego, czyli co najmniej jeden powrót jest 
niemal pewny. Niemal, bo łatwo wskazać ścieżkę o niezerowym prawdopodobieństwie, 
która prowadzi do nieskończonej ucieczki od punktu początkowego, 
ale prawdopodobieństwo tej ścieżki jest bliskie 0.


\vspace{2cm}

{\bf Dodatek:} w przypadku ruchu w trzech wymiarach, prawdopodobieństwo 
powrotu do punktu początkowego ma postać:
\begin{align*}
P_{\text{powrót}} =  \frac{1}{\pi^{3/2}} \sum_{n=1}^{\infty} \frac{1}{n^{3/2}}
\end{align*}

Szereg $1/n^{3/2}$ jest zbieżny, a jego suma to $\zeta(3/2) \approx 2.6124$, 
więc prawdopodobieństwo powrotu do punktu początkowego to 
\begin{align*}
P_{\text{powrót}} \simeq \frac{1}{\pi^{3/2}}{\zeta(3/2)} \approx \frac{2.6124}{\pi^{3/2}} \approx 0.382
\end{align*}

{\bf Uwaga:} wartość numeryczna jest mocno przybliżona, bo istotny wkład 
mają prawdopodobieństwa dla małej liczby kroków, a tam przybliżenie Stirlinga 
jest słabe.

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Przypadkowy pociąg]

W pewnym kraju po torach jeżdżą lokomotywy z numerami $1 \ldots N$. 
Po przyjeździe do tego kraju napotkaliśmy na pociąg nr 60. 
Oszacuj na podstawie tej informacji całkowitą liczbę pociągów w tym kraju. 
Rozważ też drugą wersję tego zadania, w której napotkaliśmy 5 pociągów, 
z których największy numer to 60.

\begin{solution}

Mamy przed sobą zagadnienie estymacji parametru rozkładu prawdopodobieństwa
na podstawie danych - tym zajmuje się estymacja parametryczna. 
Podstawowym narzędziem estymacji parametrycznej jest metoda największej wiarygodności,
która polega na znalezieniu parametrów rozkładu, $\mu$, które maksymalizują funkcję 
wiarygodności, czyli prawdopodobieństwo zaobserwowanych danych dla danego parametru 
rozkładu:
\begin{align*}
L(\text{dane}| \mu) = P(\text{dane}| N) = \prod_{i=1}^k P(\text{dane}_i | \mu)\\
\hat{\mu} = \arg \max_{\mu} L(\text{dane}| \mu)
\end{align*}

Pierwszym krokiem w takiej analize jest sformułowanie modelu, 
czyli rozkładu prawdopodobieństwa, który opisuje proces generowania danych.
Założymy, że rozkład prawdopodobieństwa numerów pociągów jest płaski:
\begin{align*}
P(\text{numer pociągu} = n | N) = \frac{1}{N} \text{ dla } n = 1, 2, \ldots, N
\end{align*}

Rozważmy przypadki:
\begin{itemize}
    \item pojedynczy pomiar: $n = 60$.
    W naszym przypadku funkcja wiarygodności nie zależy danych, ale dane nakładają 
    ograniczenie na możliwe wartości parametru rozkładu: $N \geq 60$.
    Wartością minimalizującą funkcję wiarygodności jest więc $N = 60$.
    Nasz estymator to $\hat{N} = N_{obs}$.
    Oszacujmy czy nasz estymator jest obciążony, czyli czy jego wartość oczekiwana 
    jest równa prawdziwej wartości parametru rozkładu:
    \begin{align*}
E[\hat{N}] = \sum_{n=1}^N n \cdot P(n|N) = \sum_{n=1}^N n \cdot 
\frac{1}{N} = \frac{1}{N} \cdot \frac{N(N+1)}{2} = \frac{N+1}{2} \neq N
    \end{align*}

    Korygujemy więc estymator, by był nieobciążony:
    \begin{align*}
\hat{N}_{unbias} = 2 \cdot N_{obs} - 1 = 2 \cdot 60 - 1 = 119
    \end{align*}

    Jest dobrze, ale słono zapłaciliśmy za tę korektę $\to$ wariancja estymatora 
    wzrosła z grubsza czterokrotnie.

    \item pięć pomiarów: $n_1, n_2, n_3, n_4, n_5$ z których największy to 60.
    W tym przypadku funkcja wiarygodności jest równa:
    \begin{align*}
     L(N) = P(n_1, n_2, n_3, n_4, n_5 | N) = \prod_{i=1}^5 P(n_i | N) = \prod_{i=1}^5 \frac{1}{N} = \frac{1}{N^5}
    \end{align*}

    Dane nakładają ograniczenie na możliwe wartości parametru rozkładu: $N \geq 60$.
    Wartością minimalizującą funkcję wiarygodności jest więc $N = 60$.
    Nasz estymator to $\hat{N} = N_{obs}$. Oszacujmy obciążenie estymatora.
    Rozkład prawdopodobieństwa największego numeru pociągu wśród 5 obserwacji jest 
    rozkładem prawdopodobieństwa maksimum z $n$ prób z rozkładu płaskiego $[0,N]$:
    Wartość oczekiwana tego rozkładu to:
    \begin{align*}
E[max|N, n] \simeq \frac{n}{n+1} \cdot N = \frac{5}{6} \cdot N
    \end{align*}

    Korygujemy więc estymator, by był nieobciążony:
    \begin{align*}
\hat{N}_{unbias} = \frac{n+1}{n} \cdot N_{obs} = \frac{6}{5} \cdot 60 = 72
    \end{align*}    
\end{itemize}

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Roztrzepana sekretarka]

Sekretarka przygotowała do wysłania $N$ listów i $N$ zaadresowanych kopert, 
ale włożyła listy do kopert w sposób przypadkowy. Ilu średnio odbiorców
dostanie swój list?

\begin{solution}

Zagadnienie możemy sformułować następująco: 
\begin{itemize}
\item N odbiorców $\to$ N prób
\item k dobrze zaadresowanych kopert $\to$ k sukcesów
\end{itemize}

W tej sytuacji rozkład pradowpodobieństwa liczby dobrze zaadresowanych kopert 
jest rozkładem wielomianowym, a jego parametrami są $N$ i prawdopodobieństwo 
sukcesu w pojedynczej próbie $p$:
\begin{align*}
P(k) = \binom{N}{k} p^k (1-p)^{N-k} &= \frac{N!}{k!(N-k)!} p^k (1-p)^{N-k} \\
<k> &= \sum_{k=0}^N k P(k) = N \cdot p = \frac{N}{N} = 1
\end{align*}

W naszym przypadku $p = \frac{1}{N}$, więc średnia liczba dobrze 
zaadresowanych kopert to 1.

\vspace{1cm}

Przypomnienie skąd się biorą człony w rozkładzie wielomianowym:
\begin{itemize}
\item liczba sposobów wyboru k dobrze zaadresowanych kopert spośród N:\\
    \begin{itemize}
    \item $N!$ - liczba permutacji N kopert, 
    \item $k!$ - liczba permutacji k dobrze zaadresowanych kopert - każda 
     z nich jest równoważna, więc musimy podzielić przez $k!$,
    \item $(N-k)!$ - liczba permutacji pozostałych N-k kopert - każda z nich 
    jest równoważna, więc musimy podzielić przez $(N-k)!$
    \end{itemize}
\item $p^k$ -- prawdopodobieństwo, że k kopert jest dobrze zaadresowanych
\item $(1-p)^{N-k}$ -- prawdopodobieństwo, że pozostałe N-k kopert jest źle zaadresowanych
\end{itemize}

\newpage
\end{solution}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Te same urodziny]

Przy jakiej minimalnej liczbie osób, N, prawdopodobieństwo tego, 
że:
\begin{enumerate}[(a)]
\item są wśród nich dwie osoby, które obchodzą urodziny tego samego dnia, 
\item ktoś ma urodziny w tym samym dniu co my, 
\end{enumerate}

wynosi nie mniej niż $1/2$?

\begin{solution}
    
a) zagadnienie rozwiążemy korzystając z dopełnienia, czyli 
obliczymy prawdopodobieństwo, że wszyscy mają różne urodziny 
i odejmiemy je od 1. Mnożymy prawdopodobieństwa, że każda 
kolejna osoba ma urodziny w innym dniu niż poprzednie osoby:
\begin{itemize}
\item pierwsza osoba może mieć urodziny w dowolnym dniu, więc mamy 1.0
\item druga osoba musi mieć urodziny w innym dniu niż pierwsza, 
      więc mamy $\frac{364}{365}$
\item trzecia osoba musi mieć urodziny w innym dniu niż pierwsza i druga,
      więc mamy $\frac{363}{365}$
\item N-ta osoba musi mieć urodziny w innym dniu niż poprzednie N-1 osób, 
      więc mamy $\frac{365-N+1}{365}$
\end{itemize}

Otrzymujemy:

\begin{align*}
P(\text{wszyscy mają różne urodziny}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \ldots \cdot \frac{365-N+1}{365} = \\
= \frac{365!}{(365-N)! \cdot 365^N}
\end{align*}

Szukamy takiego N, że $P(\text{wszyscy mają różne urodziny}) \leq \frac{1}{2}$.
Obliczenia wykonamy numerycznie używając 
\href{https://www.wolframalpha.com/input?i=table+N%5B365%21%2F%5B%28365-x%29%21*365%5Ex%5D%5D+for+x+from+10+to+25}{Wolpram Alpha}.
Wolphram szybciej wykona obliczenia niż ChatGPT, czy Gemini, ale 
Gemini daje odpowiedź w wygodniejszej formie.
%add plot
\begin{center}
\includegraphics[width=0.48\textwidth]{plots/wolphram_alpha_birthday.png}
\end{center}


W przypadku 23 osób prawdopodobieństwo, że wszyscy mają różne urodziny 
jest mniejsze niż $1/2$, więc potrzebujemy co najmniej 23 osób by 
prawdopodobieństwo tego, że są wśród nich dwie osoby, które obchodzą 
urodziny tego samego dnia było większe $1/2$.

\vspace{1cm}


b) zagadnienie możemy sformułować następująco:

\begin{itemize}
\item N osób $\to$ N prób
\item k osób ma urodziny tego samego dnia co my $\to$ k sukcesów
\end{itemize}   
 Rozkład prawdopodobieństwa liczby osób urodziny tego samego dnia co my 
jest rozkładem wielomianowym, a jego parametrami są $N$, 
i prawdopodobieństwo sukcesu w pojedynczej próbie $p$:
\begin{align*}
P(k) = \binom{N}{k} p^k (1-p)^{N-k} &= \frac{N!}{k!(N-k)!} p^k (1-p)^{N-k} 
\end{align*}

Poszukujemy $N$ takiego, że $P(k \geq 1) \geq \frac{1}{2}$, 
czyli $P(k=0) = 1 - P(k \geq 1) \leq \frac{1}{2}$.
\begin{align*}
P(k=0) = (1-p)^{N} = \left(1 - \frac{1}{365}\right)^{N} \leq \frac{1}{2} \rightarrow 
N \log(1-p) \leq \log(\frac{1}{2}) \rightarrow \\
N \geq \frac{\log(1/2)}{\log(1 - 1/365)} = 252.7
\end{align*}

Czyli potrzebujemy co najmniej 253 osób.

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Rozkręcone działo]

Działo obracające się ze stałą prędkością kątową strzela w losowo wybranej chwili. 
Wyznaczyć rozkład prawdopodobieństwa położenia punktu trafienia na ekranie 
znajdującym się w odległości $d$ od działa.


\begin{solution}
    
Zagadnienie sprowadza się do zamiany zmiennych losowych:
kąta wystrzału $\varphi$ na położenie punktu trafienia $x$ na ekranie.
Rozkład prawdopodobieństwa kąta wystrzału jest rozkładem 
jednostajnym na przedziale $[0, \pi)$:
\begin{align*}
P(\varphi) = \frac{1}{\pi}
\end{align*}

{\bf Uwaga:} Bierzemy pod uwagę tylko kąt $\varphi$ w przedziale $[0, \pi)$, ponieważ
działo trafi w ekran tylko wtedy, gdy będzie skierowane w jego stronę.

Przyjmując, że $x=0$ odpowiada kątowi $\varphi=0$, a $x$ rośnie wraz z $\varphi$,
położenie punktu trafienia $x$ na ekranie jest związane z kątem wystrzału $\varphi$
następującym wzorem:
\begin{align*}
x = d \cdot \tan(\varphi)
\end{align*}

Poszukiwany rozkład prawdopodobieństwa położenia punktu trafienia $P(x)$ 
ma postać:
\begin{align*}
P(x) = P(\varphi) \cdot \left|\frac{d\varphi}{dx}\right| = 
\frac{1}{\pi} \cdot \left|\frac{d\varphi}{dx}\right| = \\
\frac{1}{\pi} \cdot \left|\frac{d}{dx} \arctan\left(\frac{x}{d}\right)\right| = 
\frac{1}{\pi} \cdot \frac{1}{1 + \left(\frac{x}{d}\right)^2} = \\
\frac{1}{\pi} \cdot \frac{d}{d^2 + x^2}
\end{align*}

Uzyskany rozkład prawdopodobieństwa jest nazywany  rozkładem Cauchy'ego
i ma taką ciekawą właściwość, że jego wariancja jest nieskończona.

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Igła Buffona (1733)]

Rzucamy w sposób przypadkowy igłę o długości $2l$ na płaszczyznę, 
na której narysowano proste równoległe odległe o $2a$ ($a > l$). 
Jakie jest prawdopodobieństwo przecięcia przez igłę którejkolwiek prostej?

\begin{solution}
    
Wynik rzutu igłą opisujemy dwiema zmiennymi losowymi:
\begin{itemize}
\item $x$ -- odległość środka igły od najbliższej prostej
\item $\varphi$ -- kąt między igłą a prostą łączącą środek igły z najbliższą prostą
\end{itemize}

Rozkład prawdopodobieństwa tych zmiennych jest rozkładem jednostajnym na
prostokącie $[0, a] \times [0, \pi)$:
\begin{align*}
P(x, \varphi) = \frac{1}{a} \cdot \frac{2}{\pi} = \frac{1}{\pi a}
\end{align*}

Igła przetnie prostą jeśli odległość środka igły od najbliższej 
prostej będzie mniejsza niż rzut jej długości na oś prostopadłą do prostych, 
czyli $l \cdot |\cos(\varphi)|$. Musimy więc scałkować rozkład prawdopodobieństwa 
$P(x, \varphi)$ po obszarze $x < l \cdot |\cos(\varphi)|$. Efekt modułu uwzględniamy 
biorąc $\varphi$ z przedziału $[0, \pi/2)$, gdzie $\cos(\varphi)$ jest dodatnie,
i mnożąc wynik przez 2:
\begin{align*}
P = 2\int_{0}^{\pi/2} \int_{0}^{l \cdot \cos(\varphi)} P(x, \varphi) dx d\varphi = 
2  \frac{1}{\pi a} \int_{0}^{\pi/2} \int_{0}^{l \cdot \cos(\varphi)} dx d\varphi = \\
\frac{2}{\pi a} \int_{0}^{\pi/2} l \cdot \cos(\varphi) d\varphi = 
\frac{2l}{\pi a} \sin(\varphi) \Big|_{0}^{\pi/2} = \frac{2l}{\pi a}
\end{align*}

Mamy tu eksperymentalną procedurę do wyznaczenia liczby $\pi$.
Oszacujmy więc jej niepewność korzystając z procedury propagacji niepewności:
\begin{align*}
\pi = \frac{2l}{P a} \rightarrow
\Delta \pi = \sqrt{\left(\frac{\partial \pi}{\partial l} \Delta l\right)^2 + \left(\frac{\partial \pi}{\partial a} \Delta a\right)^2 + \left(\frac{\partial \pi}{\
partial P} \Delta P\right)^2} = \\
\sqrt{\left(\frac{2}{P a} \Delta l\right)^2 + \left(-\frac{2l}{P a^2} \Delta a\right)^2 + \left(-\frac{2l}{P^2 a} \Delta P\right)^2} = 
\frac{2l}{P a} \sqrt{\left(\frac{\Delta l}{l}\right)^2 + \left(\frac{\Delta a}{a}\right)^2 + \left(\frac{\Delta P}{P}\right)^2} = \\
\pi_{exp} \sqrt{\left(\frac{\Delta l}{l}\right)^2 + \left(\frac{\Delta a}{a}\right)^2 + \left(\frac{\Delta P}{P}\right)^2}
\end{align*}

Niepewności pomiaru długości igły i odległości między prostymi 
szacujemy jako najmniejszą podziałkę linijki podzieloną 
przez $\sqrt{12}$ - zakładamy płaski rozkład położenia końca
igły w przedziale najmniejszej podziałki. Mamy więc 
 $\Delta l = \Delta a = \frac{1}{\sqrt{12}} \text{mm}$. 
 Zmierzone rawdopodobieństwo $P$ to stosunek liczby trafień, $k$,
do liczby rzutów, $N$. Zakładamy, że liczba rzutów jest ustalona.
W tej sytuacji liczba trafień podlega rozkładowi dwumianowemu, 
a jego wariancja to $N \cdot P \cdot (1-P)$, więc niepewność pomiaru 
prawdopodobieństwa to:
\begin{align*}
\Delta P = \sqrt{\frac{P \cdot (1-P)}{N}} = 
\sqrt{\frac{k}{N} \cdot \left(1-\frac{k}{N}\right) \cdot \frac{1}{N}} =
\sqrt{\frac{k \cdot (N-k)}{N^3}}
\end{align*}

a niepewność względna pomiaru prawdopodobieństwa to:
\begin{align*}
\frac{\Delta P}{P} = \sqrt{\frac{1-P}{P \cdot N}} = \sqrt{\frac{N-k}{k \cdot N}} =
\sqrt{\frac{N-k}{k \cdot N}} = \sqrt{\frac{N-k}{k \cdot N}} = \sqrt{\frac{N-k}{k \cdot N}} = \sqrt{\frac{N-k}{k \cdot N}}
\end{align*}

Wartość $P$ fluktuje wokół wartości oczekiwanej $\frac{2l}{\pi a}$, więc
wkład do niepewności pomiaru $\pi$ związany z liczba rzutów maleja 
jak $1/\sqrt{N}$.

Komentarze:
\begin{enumerate}[a)]
    \item możliwość doświadczalnego wyznaczenia liczby $\pi$.
    \item wyniki doświadczeń:
    \begin{itemize}
        \item Wolf (1850) -- 5000 rzutów, $\pi = 3.1596$, 
        \item Shmit (1855) -- 3204 rzuty, $\pi = 3.1553$.
    \end{itemize}
    \item ile rzutów potrzeba, by oszacować $\pi$ z dokładnością do 
          $n$ miejsc po przecinku, czyli by wariancja estymatora $P$ była 
          mniejsza niż $10^{-2n}$?
    \item istnieje modyfikacja tego zadania: "kluska Buffona" -- rzut igłą, 
          która niekoniecznie jest prosta, lecz może mieć dowolny kształt 
          (ale taką samą długość $2l$). Co ciekawe, jest oczywiście identyczny,
          ponieważ kluczową rolę odgrywa rzut długości igły/kluski na oś prostopadłą 
          do prostych, a ten jest taki sam dla każdej igły o tej samej długości.
\end{enumerate}

\newpage
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\zadanie[Naczynie z gazem]

Rozpatrzmy gaz złożony z $N_0$ nieoddziałujących cząstek w pojemniku o 
objętości $V_0$. Wydzielmy teraz myślowo część tego pojemnika o objętości 
$V$ i oznaczmy przez $N$ liczbę cząstek gazu znajdujących się w $V$. 
Załóżmy, że każda z cząstek gazu z równym prawdopodobieństwem może 
znajdować się w dowolnym miejscu pojemnika, a zatem prawdopodobieństwo, 
że znajdzie się w $V$ wynosi $P = \frac{V}{V_0}$.
\vspace{1cm}
\begin{enumerate}[a)]
    \item Jaka jest średnia liczba cząstek w $V$? Odpowiedź wyraź poprzez $N_0$, $V_0$ i $V$.
    \item Znajdź względną dyspersję $\frac{<(N - <N>)^2>}{<N>^2}$. Odpowiedź wyraź poprzez $<N>$, $V_0$ i $V$.
    \item Jak wygląda odpowiedź z punktu b) kiedy $V \ll V_0$?
    \item Spróbuj przewidzieć, jaką wartość powinna osiągać dyspersja $<(N - <N>)^2>$ kiedy $V \to V_0$. Czy odpowiedź z punktu b) zgadza się z tymi przewidywaniami?
\end{enumerate}


\begin{solution}

\begin{enumerate}[a)]
    \item Jaka jest średnia liczba cząstek w $V$? \\
     Zagadnienie formułujemy jako problem wielomianowy: 
     jaka jest średnia liczba sukcesów (cząstek w $V$) w $N_0$ próbach (cząstkach)?
     \begin{align*}
        <N> = N_0 \cdot P = N_0 \cdot \frac{V}{V_0}
     \end{align*}

    \item Względna dyspersja $\frac{<(N - <N>)^2>}{<N>^2}$. \\
    Kontynuujemy rozważania z punktu widzenia rozkładu wielomianowego.
    Dyspersja rozkładu wielomianowego to $N_0 \cdot P \cdot (1-P)$, więc:
    \begin{align*}
        \frac{<(N - <N>)^2>}{<N>^2} = \frac{N_0 \cdot P \cdot (1-P)}{(N_0 \cdot P)^2} = 
        \frac{1-P}{N_0 \cdot P} = 
        \frac{1 - (V / V_0)}{<N>}
    \end{align*}
 
    \item Jak wygląda względna dyspersja dla  $V \ll V_0$?
    \begin{align*}
        \frac{<(N - <N>)^2>}{<N>^2} = \frac{1 - (V / V_0)}{<N>} \approx \frac{1}{<N>}
    \end{align*}

    \item Szacujemy dyspersję dla  $V \to V_0$. 
    W sytuacji gdy $V$ zbliża się do $V_0$ wszystkie 
    cząstki powinny znajdować się w $V$ i nie ma żadnych fluktuacji, 
    więc dyspersja będzie dążyć do 0. Odpowiedź z punktu b) zgadza się z tym przewidywaniem, ponieważ
    \begin{align*}
        \frac{<(N - <N>)^2>}{<N>^2} = \frac{1 - (V / V_0)}{<N>} \to 0
    \end{align*}
\end{enumerate}

\end{solution}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
